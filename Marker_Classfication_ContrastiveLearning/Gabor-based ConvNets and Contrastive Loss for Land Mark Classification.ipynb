{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gabor-Based Convolutional Neural Network\n",
    "## trained using supervised contrastive loss\n",
    "## for protein landmark classification\n",
    "* [Imports and Utility Functions](#first-bullet)\n",
    "* [Creating Custom Gabor2D Conv Layer](#second-bullet)\n",
    "* [Model Definition](#third-bullet)\n",
    "* [Contrastive Loss Definition](#fourth-bullet)\n",
    "* [Model Training](#fifth-bullet)\n",
    "* [Visualize Learned Representation](#sixth-bullet)\n",
    "* [Confusion Matrix](#seventh-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Utility Functions <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Input, Flatten,Lambda, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.keras.utils import conv_utils\n",
    "from tensorflow.python.keras.engine.input_spec import InputSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single cell image height and width\n",
    "IMG_WIDTH = 100 \n",
    "IMG_HEIGHT = 100\n",
    "#training batch size\n",
    "BATCH_SIZE = 4\n",
    "#note batch size was small due toe memory limitation the gpu used\n",
    "# GeForce GTX 1050 Ti\n",
    "\n",
    "# utility functions\n",
    "def get_tfrecords_path_list(tf_record_path):\n",
    "    # get *tfrecords in given path\n",
    "    _,_,fnames = next(os.walk(tf_record_path))\n",
    "    file_list = []\n",
    "    for f in fnames:\n",
    "        file_list.append(os.path.join(tf_record_path,f))\n",
    "    return file_list\n",
    "\n",
    "def img_augment(img):\n",
    "    # randomly flip image\n",
    "    flip_chance = tf.random.uniform([],minval=0,maxval=4,dtype=tf.int32)\n",
    "    if flip_chance == 1:\n",
    "        img = tf.image.flip_left_right(img)\n",
    "  \n",
    "    flip_chance = tf.random.uniform([],minval=0,maxval=4,dtype=tf.int32)\n",
    "    if flip_chance == 1:\n",
    "        img = tf.image.flip_up_down(img)\n",
    " \n",
    "    rot_chance = tf.random.uniform([],minval=0,maxval=4,dtype=tf.int32)\n",
    "    if rot_chance == 1:\n",
    "        img = tf.image.rot90(img)\n",
    "    return img\n",
    "\n",
    "def decode_image(image,width,height):\n",
    "    # decode string bytes \n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.reshape(image, [width,height, 3])\n",
    "    return image\n",
    "\n",
    "#define features stored in tfrecords\n",
    "features={'img_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "'label': tf.io.FixedLenFeature([], tf.int64)}\n",
    "def _parse_function(raw_record):\n",
    "    sample = tf.io.parse_single_example(raw_record, features)\n",
    "    img_string = sample['img_raw']\n",
    "    img = tf.io.decode_raw(img_string,tf.uint8)\n",
    "    img = tf.cast(img,tf.float32)/255.0\n",
    "    img = tf.reshape(img,(IMG_HEIGHT,IMG_WIDTH,1))\n",
    "    img = img_augment(img)\n",
    "    label = tf.cast(sample[\"label\"],tf.float32)\n",
    "#     label = tf.one_hot(label,5)\n",
    "    return img ,label \n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def get_dataset(filenames_list,augment=False):\n",
    "    raw_dataset = tf.data.TFRecordDataset(filenames_list)\n",
    "    dataset = raw_dataset.map(_parse_function)\n",
    "    dataset = dataset.shuffle(4096)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths to tfrecords \n",
    "# 4 repeatitions for training\n",
    "# 1 repeatition for validation\n",
    "train_tfrecord_path1 = r'D:\\Phenix\\EO_20190317_mCherryColocRep1__2019-03-17T18_04_08-Measurement 1\\markers_tf_records'\n",
    "train_tfrecord_path2 = r'D:\\Phenix\\EO_20190319_mCherryColocRep2__2019-03-19T16_55_51-Measurement 1\\markers_tf_records'\n",
    "train_tfrecord_path3 = r'D:\\Phenix\\EO_20190319_mCherryColocRep2__2019-03-19T20_47_51-Measurement 2\\markers_tf_records'\n",
    "train_tfrecord_path4 = r'D:\\Phenix\\EO_20190321_mCherryColocRep3__2019-03-21T16_17_40-Measurement 1\\markers_tf_records'\n",
    "valid_tfrecord_path = r'D:\\Phenix\\EO_20190321_mCherryColocRep3__2019-03-21T21_11_35-Measurement 2\\markers_tf_records'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list1 = get_tfrecords_path_list(train_tfrecord_path1)\n",
    "file_list2 = get_tfrecords_path_list(train_tfrecord_path2)\n",
    "file_list3 = get_tfrecords_path_list(train_tfrecord_path3)\n",
    "file_list4 = get_tfrecords_path_list(train_tfrecord_path4)\n",
    "#combine tfrecords paths list for all 4 reps\n",
    "file_list = file_list1 + file_list2 + file_list3 + file_list4\n",
    "valid_list = get_tfrecords_path_list(valid_tfrecord_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert lists of tfrecords into training and validation datset\n",
    "train_dataset = get_dataset(file_list)\n",
    "valid_dataset = get_dataset(valid_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Custom Gabor2D Conv Layer <a class=\"anchor\" id=\"second-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gabor_filter(shape, sigma=1.0, theta=20, lambd=15.0, gamma=0.5):\n",
    "    \"\"\"Return a gabor filter.\"\"\"\n",
    "    params = {\n",
    "        'ksize': shape,\n",
    "        'sigma': sigma,\n",
    "        'theta': theta,\n",
    "        'lambd': lambd,\n",
    "        'gamma': gamma\n",
    "    }\n",
    "    gabor_filter = cv2.getGaborKernel(**params)\n",
    "    return gabor_filter\n",
    "\n",
    "\n",
    "class GaborConv2D(Conv2D):\n",
    "    \"\"\"Class GaborConv2D\n",
    "       Custom Conv2D with constant gabor filter included.\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super(GaborConv2D, self).__init__(filters, kernel_size, **kwargs)\n",
    "        print(self.kernel_size)\n",
    "        if np.size(kernel_size) == 1:\n",
    "            self.kernelB_init_weight = _gabor_filter(shape=(kernel_size, kernel_size))\n",
    "        else:\n",
    "            self.kernelB_init_weight = _gabor_filter(kernel_size)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_shape = tensor_shape.TensorShape(input_shape)\n",
    "        input_channel = self._get_input_channel(input_shape)\n",
    "        kernel_shape = self.kernel_size + (input_channel, self.filters)\n",
    "\n",
    "        self.kernelA = self.add_weight(\n",
    "            name='kernelA',\n",
    "            shape=kernel_shape,\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "            trainable=True,\n",
    "            dtype=self.dtype)\n",
    "\n",
    "        self.kernelB = K.constant(self.kernelB_init_weight)\n",
    "        self.kernel = K.transpose(K.dot(K.transpose(self.kernelA), self.kernelB))\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(\n",
    "                name='bias',\n",
    "                shape=(self.filters,),\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "                trainable=True,\n",
    "                dtype=self.dtype)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        channel_axis = self._get_channel_axis()\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_channel})\n",
    "\n",
    "        self._build_conv_op_input_shape = input_shape\n",
    "        self._build_input_channel = input_channel\n",
    "        self._padding_op = self._get_padding_op()\n",
    "        self._conv_op_data_format = conv_utils.convert_data_format(\n",
    "            self.data_format, self.rank + 2)\n",
    "        self._convolution_op = nn_ops.Convolution(\n",
    "            input_shape,\n",
    "            filter_shape=self.kernel.shape,\n",
    "            dilation_rate=self.dilation_rate,\n",
    "            strides=self.strides,\n",
    "            padding=self._padding_op,\n",
    "            data_format=self._conv_op_data_format)\n",
    "        self.built = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition <a class=\"anchor\" id=\"third-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5  \n",
    "input_shape = (100,100,1)\n",
    "def create_encoder():\n",
    "    input_x = Input(input_shape)\n",
    "    x = GaborConv2D(128,kernel_size=(3,3),strides=(1,1),activation='relu',padding='same')(input_x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(128,3,activation='relu',padding='same')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(128,3,activation='relu',padding='same')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(128,3,activation='relu',padding='same')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(128,3,activation='relu',padding='same')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    model = Model(input_x ,x,name='convnet_encoder')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder + Classifier Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(encoder, trainable=True):\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    features = Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = Dropout(dropout_rate)(features)\n",
    "    outputs = Dense(num_classes, activation=\"softmax\")(features)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"convnet-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contastive Loss Definition <a class=\"anchor\" id=\"fourth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a projecting head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_projection_head(encoder):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    outputs = tf.keras.layers.Dense(projection_units, activation=\"relu\")(features)\n",
    "    model = tf.keras.Model(\n",
    "        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training <a class=\"anchor\" id=\"fifth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Train encoder using Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_encoder()\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "encoder_with_projection_head.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "    loss=SupervisedContrastiveLoss(temperature),\n",
    ")\n",
    "history = encoder_with_projection_head.fit(\n",
    "    train_dataset, epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Save Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save('trained_encoder.tf',save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Create Classifier using pre-trained encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = create_classifier(encoder, trainable=False)\n",
    "history = classifier.fit(train_dataset, epochs=10)\n",
    "# check accuracy on validation set\n",
    "accuracy = classifier.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Save Fully Trained Classifying Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('trained_classifier.tf',save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Learned Representation <a class=\"anchor\" id=\"sixth-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_path = r'D:\\Phenix\\EO_20190321_mCherryColocRep3__2019-03-21T21_11_35-Measurement 2\\experiment_green_tfrecords';\n",
    "experiment_tf_records = get_tfrecords_path_list(experiment_path)\n",
    "experiment_dataset = get_dataset(experiment_tf_records)\n",
    "\n",
    "for batch in experiment_dataset:\n",
    "    break\n",
    "labels = batch[1]\n",
    "outputs = encoder(batch[0])\n",
    "for batch in experiment_dataset:\n",
    "    current_labels = batch[1]\n",
    "    current_outputs = encoder(batch[0])\n",
    "    print(current_outputs.shape)\n",
    "    outputs = np.vstack([outputs, current_outputs])\n",
    "    labels = np.hstack([labels, current_labels])\n",
    "#Represenations and labels are small enough to be saved as a numpy array\n",
    "np.save('Experiment_features',outputs)\n",
    "np.save('Experment_labels',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=3)\n",
    "X_embeddins = tsne.fit_transform(outputs)\n",
    "plt.figure(figsize=(30,30))\n",
    "fig,ax = plt.subplots()\n",
    "test  = plt.scatter(X_embeddins[:,0],X_embeddins[:,2],c=labels, cmap='Spectral')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix <a class=\"anchor\" id=\"seventh-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "import seaborn as sns\n",
    "\n",
    "y_true = batch[1]\n",
    "y_pred = np.argmax(classifier.predict(batch[0]),axis=1)\n",
    "\n",
    "for batch in valid_dataset:\n",
    "    current_labels = batch[1]\n",
    "    current_preds = np.argmax(classifier.predict(batch[0]),axis=1)\n",
    "\n",
    "    y_pred = np.hstack([y_pred, current_preds])\n",
    "    y_true = np.hstack([y_true, current_labels])\n",
    "    \n",
    "plt.figure(figsize=(10,10))\n",
    "cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.9, dark=0, as_cmap=True)\n",
    "keys = ['MitoTracker', 'mChActA', 'mChCb5','ChPTDSS1','mCardinal']\n",
    "sns.set(font_scale=2)\n",
    "ax = sns.heatmap(c, annot=True,xticklabels=keys,yticklabels=keys, fmt=\"g\",cmap=cmap,square=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfgpu] *",
   "language": "python",
   "name": "conda-env-tfgpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
